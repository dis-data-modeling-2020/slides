{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIS08 - Handling Different File Formats like CSV and JSON in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Jupyter notebook is based on chapter 16 of [Automatic the Boring Stuff with Python](https://automatetheboringstuff.com/2e/chapter16/) and the tutorials of [RealPython.com](https://realpython.com/python-json).\n",
    "\n",
    "CSV and JSON are common plaintext formats for storing data. They are easy for programs to parse while still being human readable, so they are often used for simple spreadsheets or web app data. The `csv` and `json` modules greatly simplify the process of reading and writing to CSV and JSON files.\n",
    "\n",
    "The last lectures have taught you how to use Python to parse information from a wide variety of file formats. One common task is taking data from a variety of formats and parsing it for the particular information you need. These tasks are often specific to the point that commercial software is not optimally helpful. By writing your own scripts, you can make the computer handle large amounts of data presented in these formats.\n",
    "\n",
    "\n",
    "## PART I: CSV Files - The CSV Module\n",
    "\n",
    "Remeber: Each line in a CSV file represents a row in the spreadsheet, and commas separate the cells in the row. CSV files are simple, lacking many of the features of an Excel spreadsheet. For example, CSV files\n",
    "\n",
    "* Don’t have types for their values—everything is a string\n",
    "* Don’t have settings for font size or color\n",
    "* Don’t have multiple worksheets\n",
    "* Can’t specify cell widths and heights\n",
    "* Can’t have merged cells\n",
    "* Can’t have images or charts embedded in them\n",
    "\n",
    "In the last lecture you learned to parse CSV file \"the hard way\", without any special support from a specific module. Not every comma in a CSV file represents the boundary between two cells. CSV files also have their own set of escape characters to allow commas and other characters to be included as part of the values. The `split()` method doesn’t handle these escape characters. \n",
    "\n",
    "This will change today. Enter, __The CSV Module__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The csv module comes with Python, so we can import it right away\n",
    "import csv\n",
    "# first open the CSV file\n",
    "exampleFile = open('lotr_clean.csv')\n",
    "# create a reader object and specify the delimiter used (comma is the default)\n",
    "exampleReader = csv.reader(exampleFile, delimiter=';')\n",
    "# such a reader object can be converted to a normal Python list\n",
    "exampleData = list(exampleReader)\n",
    "# show the content of this list\n",
    "exampleData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you see here is a __two dimensional list__, or in other words: A list that contains other lists! \n",
    "\n",
    "Now that you have the CSV file as a list of lists, you can access the value at a particular row and column with the expression `exampleData[row][col]`, where `row` is the index of one of the lists in exampleData, and `col` is the index of the item you want from that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the second column element of the second row\n",
    "exampleData[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data from Reader Objects in a for Loop\n",
    "For large CSV files, you’ll want to use the Reader object in a for loop. This avoids loading the entire file into memory at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "exampleFile = open('lotr_clean.csv')\n",
    "exampleReader = csv.reader(exampleFile, delimiter=';')\n",
    "for row in exampleReader:\n",
    "    print('Row #' + str(exampleReader.line_num) + ' ' + str(row[2]))\n",
    "    # What do we have to do to show just the dialogs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you import the `csv module and make a `Reader` object from the CSV file, you can loop through the rows in the Reader object. Each row is a list of values, with each value representing a cell.\n",
    "\n",
    "The `print()` function call prints the number of the current row and the contents of the row. To get the row number, use the Reader object’s `line_num` variable, which contains the number of the current line.\n",
    "\n",
    "The `Reader` object can be looped over only once. To reread the CSV file, you must call csv.reader to create a Reader object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writer Objects\n",
    "\n",
    "A `Writer` object lets you write data to a CSV file. To create a `Writer` object, you use the `csv.writer()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# First, call open() and pass it 'w' to open a file in write mode\n",
    "# The newline='' is to pass around a Windows bug... Just include it.\n",
    "outputFile = open('output.csv', 'w', newline='')\n",
    "# This will create the object you can then pass to csv.writer() to create a Writer object.\n",
    "outputWriter = csv.writer(outputFile, delimiter=',')\n",
    "# writerow takes a list as an argument\n",
    "outputWriter.writerow(['spam', 'eggs', 'bacon', 'ham'])\n",
    "outputWriter.writerow(['Hello, world!', 'eggs', 'bacon', 'ham'])\n",
    "outputWriter.writerow([1, 2, 3.141592, 4])\n",
    "# close the file at the end!\n",
    "outputFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the `Writer` object automatically escapes the comma in the value `'Hello, world!'` with double quotes in the CSV file. __The csv module saves you from having to handle these special cases yourself__.\n",
    "\n",
    "Are you still awake? Quiz time!\n",
    "\n",
    "* How do you write CSV files that use semicolons instead of commas?\n",
    "* How do you write CSV files that use tabulator spaces instead of commas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Removing the Header from CSV Files\n",
    "\n",
    "Now we will finally start to use Python for something useful - we would like to remove the header from CSV files. Of course, for one single file, we don't need a Python progam to do this. But think of a folder full of hundreds of CSV files! For these repetitive task, Python is the perfect tool! Think again about the inital XKCD comic I showed you.\n",
    "\n",
    "![XCDK - Is it worth the time?](https://imgs.xkcd.com/comics/is_it_worth_the_time.png \"XCDK - Is it worth the time?\")\n",
    "\n",
    "The program will need to open every file with the .csv extension in the current working directory, read in the contents of the CSV file, and rewrite the contents without the first row to a file of the same name. This will replace the old contents of the CSV file with the new, headless contents.\n",
    "\n",
    "### Step 0: Make a plan!\n",
    "\n",
    "As always, whenever you write a program that modifies files, be sure to back up the files, first just in case your program does not work the way you expect it to. You don’t want to accidentally erase your original files.\n",
    "\n",
    "At a *high level*, the program must do the following:\n",
    "\n",
    "1. Find all the CSV files in the current working directory.\n",
    "2. Read in the full contents of each file.\n",
    "3. Write out the contents, skipping the first line, to a new CSV file.\n",
    "\n",
    "At the *code level*, this means the program will need to do the following:\n",
    "\n",
    "1. Loop over a list of files from `os.listdir()`, skipping the non-CSV files.\n",
    "2. Create a CSV Reader object and read in the contents of the file, using the `line_num` attribute to figure out which line to skip.\n",
    "3. Create a CSV Writer object and write out the read-in data to the new file.\n",
    "\n",
    "For this project, open a new file editor window and save it as `removeCsvHeader.py`.\n",
    "\n",
    "![](https://i.imgur.com/C4M9azM.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Loop Through Each CSV File\n",
    "\n",
    "The `os.makedirs()` call will create a `headerRemoved` folder where all the headless CSV files will be written. A `for` loop on `os.listdir('.')` gets you partway there, but it will loop over all files in the working directory, so you’ll need to add some code at the start of the loop that skips filenames that don’t end with `.csv`. The `continue` statement makes the for loop move on to the next filename when it comes across a non-CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python3\n",
    "# removeCsvHeader.py - Removes the header from all CSV files in the current\n",
    "# working directory.\n",
    "\n",
    "import csv, os\n",
    "\n",
    "os.makedirs('headerRemoved', exist_ok=True)\n",
    "\n",
    "# Loop through every file in the current working directory.\n",
    "for csvFilename in os.listdir('.'):\n",
    "    if not csvFilename.endswith('.csv'):\n",
    "        continue    # skip non-csv files\n",
    "\n",
    "    print('Removing header from ' + csvFilename + '...')\n",
    "\n",
    "    # TODO: Read the CSV file in (skipping first row).\n",
    "\n",
    "    # TODO: Write out the CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Read in the CSV File\n",
    "\n",
    "The program doesn’t remove the first line from the CSV file. Rather, it creates a new copy of the CSV file without the first line. Since the copy’s filename is the same as the original filename, the copy will overwrite the original.\n",
    "\n",
    "The program will need a way to track whether it is currently looping on the first row. Add the following to `removeCsvHeader.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python3\n",
    "# removeCsvHeader.py - Removes the header from all CSV files in the current\n",
    "# working directory.\n",
    "\n",
    "import csv, os\n",
    "\n",
    "os.makedirs('headerRemoved', exist_ok=True)\n",
    "\n",
    "# Loop through every file in the current working directory.\n",
    "for csvFilename in os.listdir('.'):\n",
    "    if not csvFilename.endswith('.csv'):\n",
    "        continue    # skip non-csv files\n",
    "\n",
    "    print('Removing header from ' + csvFilename + '...')\n",
    "\n",
    "    # Read the CSV file in (skipping first row).\n",
    "    csvRows = []\n",
    "    csvFileObj = open(csvFilename)\n",
    "    readerObj = csv.reader(csvFileObj, delimiter=';')\n",
    "    for row in readerObj:\n",
    "        if readerObj.line_num == 1:\n",
    "            continue    # skip first row\n",
    "        csvRows.append(row)\n",
    "    csvFileObj.close()\n",
    "\n",
    "    # TODO: Write out the CSV file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Reader` object’s `line_num` attribute can be used to determine which line in the CSV file it is currently reading. Another for loop will loop over the rows returned from the CSV `Reader` object, and all rows but the first will be appended to `csvRows`.\n",
    "\n",
    "As the `for` loop iterates over each row, the code checks whether `readerObj.line_num` is set to `1`. If so, it executes a `continue` to move on to the next row without appending it to `csvRows`. For every row afterward, the condition will be always be `False`, and the row will be appended to `csvRows`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Write Out the CSV File Without the First Row\n",
    "\n",
    "Now that csvRows contains all rows but the first row, the list needs to be written out to a CSV file in the headerRemoved folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#! python3\n",
    "# removeCsvHeader.py - Removes the header from all CSV files in the current\n",
    "# working directory.\n",
    "\n",
    "import csv, os\n",
    "\n",
    "os.makedirs('headerRemoved', exist_ok=True)\n",
    "\n",
    "# Loop through every file in the current working directory.\n",
    "for csvFilename in os.listdir('.'):\n",
    "    if not csvFilename.endswith('.csv'):\n",
    "        continue    # skip non-csv files\n",
    "\n",
    "    print('Removing header from ' + csvFilename + '...')\n",
    "\n",
    "    # Read the CSV file in (skipping first row).\n",
    "    csvRows = []\n",
    "    csvFileObj = open(csvFilename)\n",
    "    readerObj = csv.reader(csvFileObj, delimiter=';')\n",
    "    for row in readerObj:\n",
    "        if readerObj.line_num == 1:\n",
    "            continue    # skip first row\n",
    "        csvRows.append(row)\n",
    "    csvFileObj.close()\n",
    "\n",
    "    # Write out the CSV file.\n",
    "    csvFileObj = open(os.path.join('headerRemoved', csvFilename), 'w', newline='')\n",
    "    csvWriter = csv.writer(csvFileObj)\n",
    "    for row in csvRows:\n",
    "        csvWriter.writerow(row)\n",
    "    csvFileObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CSV `Writer` object will write the list to a CSV file in `headerRemoved` using `csvFilename` (which we also used in the CSV reader). This will overwrite the original file.\n",
    "\n",
    "Once we create the `Writer` object, we loop over the sublists stored in `csvRows` and write each sublist to the file.\n",
    "\n",
    "After the code is executed, the outer `for` loop will loop to the next filename from `os.listdir('.')`. When that loop is finished, the program will be complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART II: JSON\n",
    "\n",
    "__JavaScript Object Notation__ is a popular way to format data as a single human-readable string. JSON is the native way that JavaScript programs write their data structures and usually resembles what Python’s `pprint()` function would produce. You don’t need to know JavaScript in order to work with JSON-formatted data.\n",
    "\n",
    "Here’s an example of data formatted as JSON:\n",
    "\n",
    "``` {\"name\": \"Zophie\", \"isCat\": true, \"miceCaught\": 0, \"napsTaken\": 37.5, \"felineIQ\": null}```\n",
    "\n",
    "JSON is useful to know, because many websites offer JSON content as a way for programs to interact with the website. This is known as providing an _application programming interface_ (API). Accessing an API is the same as accessing any other web page via a URL. The difference is that the data returned by an API is formatted (with JSON, for example) for machines; APIs aren’t easy for people to read.\n",
    "\n",
    "Many websites make their data available in JSON format. Facebook, Twitter, Yahoo, Google, Tumblr, Wikipedia, Flickr, Data.gov, Reddit, IMDb, Rotten Tomatoes, LinkedIn, and many other popular sites offer APIs for programs to use. Some of these sites require registration, which is almost always free. You’ll have to find documentation for what URLs your program needs to request in order to get the data you want, as well as the general format of the JSON data structures that are returned. This documentation should be provided by whatever site is offering the API; if they have a “Developers” page, look for the documentation there.\n",
    "\n",
    "Using APIs, you could write programs that do the following:\n",
    "\n",
    "* Scrape raw data from websites. (Accessing APIs is often more convenient than downloading web pages and parsing HTML with Beautiful Soup.)\n",
    "* Automatically download new posts from one of your social network accounts and post them to another account. For example, you could take your Tumblr posts and post them to Facebook.\n",
    "* Create a “movie encyclopedia” for your personal movie collection by pulling data from IMDb, Rotten Tomatoes, and Wikipedia and putting it into a single text file on your computer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing JSON\n",
    "\n",
    "JSON is built on two structures:\n",
    "\n",
    "* A collection of _name/value pairs_. In various languages, this is realized as an object, record, struct, dictionary, hash table, keyed list, or associative array.\n",
    "* An _ordered list of values_. In most languages, this is realized as an array, vector, list, or sequence.\n",
    "\n",
    "All details can be found online: https://www.json.org\n",
    "\n",
    "#### Objects\n",
    "An `object` is an unordered set of name/value pairs. An object begins with `{` (left brace) and ends with `}` (right brace). Each name is followed by `:` (colon) and the name/value pairs are separated by `,` (comma).\n",
    "![](https://www.json.org/img/object.png)\n",
    "\n",
    "#### Arrays\n",
    "An `array` is an ordered collection of values. An array begins with `[` (left bracket) and ends with `]` (right bracket). Values are separated by `,` (comma).\n",
    "![](https://www.json.org/img/array.png)\n",
    "\n",
    "#### Values\n",
    "A `value` can be a `string` in double quotes, or a `number`, or `true` or `false` or `null`, or an `object` or an `array`. These structures can be nested.\n",
    "![](https://www.json.org/img/value.png)\n",
    "\n",
    "#### Strings\n",
    "A `string` is a sequence of zero or more Unicode characters, wrapped in double quotes, using backslash escapes. A character is represented as a single character string.\n",
    "![](https://www.json.org/img/string.png)\n",
    "\n",
    "#### Numbers\n",
    "A `number` is a combination of digits. \n",
    "![](https://www.json.org/img/number.png)\n",
    "\n",
    "Whitespace can be inserted between any pair of tokens. Excepting a few encoding details, that completely describes the language.\n",
    "\n",
    "#### Example JSON Data\n",
    "\n",
    "``` json\n",
    "{\n",
    "    \"firstName\": \"Philipp\",\n",
    "    \"hobbies\": [\"Mac\", \"Python\", \"dank memes\", \"BBQ\"],\n",
    "    \"age\": 40,\n",
    "    \"children\": [\n",
    "        {\n",
    "            \"firstName\": \"Primus\",\n",
    "            \"age\": 4\n",
    "        },\n",
    "        {\n",
    "            \"firstName\": \"Secundus\",\n",
    "            \"age\": 1\n",
    "        }\n",
    "    ]\n",
    "}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The JSON Module\n",
    "\n",
    "Python’s `json` module handles all the details of translating between a string with JSON data and Python values for the `json.loads()`/`json.load()` and `json.dumps()`/`json.dump()` functions. JSON can’t store every kind of Python value. It can contain values of only the following data types: strings, integers, floats, Booleans, lists, dictionaries, and NoneType. JSON cannot represent Python-specific objects, such as File objects, CSV Reader or Writer objects, Regex objects, or Selenium WebElement objects.\n",
    "\n",
    "We have to seperate two different type of working with JSON:\n",
    "\n",
    "* The process of encoding JSON is usually called __serialization__. This term refers to the transformation of data into a series of bytes (hence serial) to be stored or transmitted across a network. \n",
    "* Naturally, __deserialization__ is the inverse process of decoding data that has been stored or delivered in the JSON standard.\n",
    "\n",
    "In other word: __Serialization is writing JSON data__ and __deserialization is reading JSON data__. Let's start with the reading.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading JSON with the loads() Function\n",
    "\n",
    "To translate a string containing JSON data into a Python value, pass it to the `json.loads()` function. (The name means “load string,” not “loads.”)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringOfJsonData = '''{\n",
    "    \"firstName\": \"Philipp\",\n",
    "    \"hobbies\": [\"Mac\", \"Python\", \"dank memes\", \"BBQ\"],\n",
    "    \"age\": 40,\n",
    "    \"children\": [\n",
    "        {\n",
    "            \"firstName\": \"Primus\",\n",
    "            \"age\": 4\n",
    "        },\n",
    "        {\n",
    "            \"firstName\": \"Secundus\",\n",
    "            \"age\": 1\n",
    "        }\n",
    "    ]\n",
    "}'''\n",
    "import json\n",
    "jsonDataAsPythonValues = json.loads(stringOfJsonData)\n",
    "jsonDataAsPythonValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you import the `json` module, you can call `loads()` and pass it a string of JSON data. Note that JSON strings always use double quotes. It will return that data as a Python dictionary. Python dictionaries are not ordered, so the key-value pairs may appear in a different order when you print `jsonDataAsPythonValue`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "children = jsonDataAsPythonValues.get('children')\n",
    "for child in children:\n",
    "    print(str(child.get('firstName')) + ' is ' + str(child.get('age')) + ' years old.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping JSON to Python\n",
    "\n",
    "| Python  | JSON | Python |\n",
    "| ------------- | ------------- | ------------- |\n",
    "| dict\t| object | dict |\n",
    "| list, tuple\t| array| list | \n",
    "| str\t| string| str |\n",
    "| int   | number| int|\n",
    "| float | number| float|\n",
    "| True\t| true| True|\n",
    "| False\t| false| False|\n",
    "| None\t| null| None |\n",
    "\n",
    "Technically, this conversion isn’t a perfect inverse from the first to the last column. That basically means that if you encode an object now and then decode it again later, you may not get exactly the same object back. I imagine it’s a bit like teleportation: break my molecules down over here and put them back together over there. Am I still the same person?\n",
    "\n",
    "### Writing JSON to files\n",
    "\n",
    "What happens after a computer processes lots of information? It needs to take a data dump. Accordingly, the json library exposes the `dump()` method for writing data to files. There is also a `dumps()` method (pronounced as “dump-s”) for writing to a Python string.\n",
    "\n",
    "Simple Python objects are translated to JSON according to a fairly intuitive conversion.\n",
    "\n",
    "#### Interlude: Opening files with the `with` statement\n",
    "In Python you need to give access to a file by opening it. You can do it by using the `open()` function. Open returns a file object, which has methods and attributes for getting information about and manipulating the opened file. \n",
    "\n",
    "With the `with` statement, you get better syntax and exceptions handling. The `with` statement simplifies exception handling by encapsulating common preparation and cleanup tasks. In addition, it will automatically close the file. The with statement provides a way for ensuring that a clean-up is always used.\n",
    "\n",
    "Without the `with` statement, we would write something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example without with\n",
    "file = open('lotr_clean.csv')\n",
    "data = file.read()\n",
    "print(data)\n",
    "file.close()  # It's important to close the file when you're done with it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening a file using `with` is as simple as: `with open(filename) as file:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lotr_clean.csv') as file: # Use file to refer to the file object\n",
    "    data = file.read()\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Serialization Example\n",
    "\n",
    "Imagine you’re working with a Python object in memory. We just reuse the `jsonDataAsPythonValues`. It is critical that you save this information to disk, so your mission is to write it to a file.\n",
    "\n",
    "Using Python’s context manager, you can create a file called `samplefile.json` and open it in write mode. Note that `dump()` takes two positional arguments:\n",
    "\n",
    "1. the data object to be serialized, and \n",
    "2. the file-like object to which the bytes will be written.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"samplefile.json\", \"w\") as write_file:\n",
    "    # we export/dump the jsonDataAsPythonValues from the earlier example into a file\n",
    "    json.dump(jsonDataAsPythonValues, write_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, if you were so inclined as to continue using this serialized JSON data in your program, you could write it to a native Python str object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = json.dumps(jsonDataAsPythonValues)\n",
    "print(jsonDataAsPythonValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Real-World Example - Data from Web-APIs\n",
    "\n",
    "For your introductory example, you’ll use [JSONPlaceholder](https://jsonplaceholder.typicode.com), a great source of __fake JSON data for practice purposes__.\n",
    "\n",
    "You’ll need to make an API request to the JSONPlaceholder service, so just use the requests package to do the heavy lifting. Add these imports at the top of your file: `json` and `request`.\n",
    "\n",
    "Go ahead and make a request to the JSONPlaceholder API for the `/todos` endpoint. If you’re unfamiliar with `requests`, there’s actually a handy `json()` method that will do all of the work for you, but you can practice using the `json` library to deserialize the text attribute of the response object. It should look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n",
    "todos = json.loads(response.text)\n",
    "\n",
    "# or try the following to directly parse the request result as a json object\n",
    "# todos = response.json()\n",
    "\n",
    "# Take a look at the first 3\n",
    "todos[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, time for some action. You can see the structure of the data by visiting the endpoint in a browser: https://jsonplaceholder.typicode.com/todos \n",
    "\n",
    "Here’s a sample TODO:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"userId\": 1,\n",
    "    \"id\": 1,\n",
    "    \"title\": \"delectus aut autem\",\n",
    "    \"completed\": false\n",
    "}\n",
    "```\n",
    "\n",
    "There are multiple users, each with a unique userId, and each task has a Boolean completed property. __Can you determine which users have completed the most tasks?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map of userId to number of complete TODOs for that user\n",
    "todos_by_user = {}\n",
    "\n",
    "# Increment complete TODOs count for each user.\n",
    "for todo in todos:\n",
    "    if todo[\"completed\"]:\n",
    "        try:\n",
    "            # Increment the existing user's count.\n",
    "            todos_by_user[todo[\"userId\"]] += 1\n",
    "        except KeyError:\n",
    "            # This user has not been seen. Set their count to 1.\n",
    "            todos_by_user[todo[\"userId\"]] = 1\n",
    "\n",
    "# Create a sorted list of (userId, num_complete) pairs.\n",
    "top_users = sorted(todos_by_user.items(), \n",
    "                   key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(top_users)\n",
    "\n",
    "# Get the maximum number of complete TODOs.\n",
    "max_complete = top_users[0][1]\n",
    "\n",
    "# Create a list of all users who have completed\n",
    "# the maximum number of TODOs.\n",
    "users = []\n",
    "for user, num_complete in top_users:\n",
    "    if num_complete < max_complete:\n",
    "        break\n",
    "    users.append(str(user))\n",
    "\n",
    "max_users = \" and \".join(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An alternative way to print text and variables with out concatinations (+)!\n",
    "# The leading f marks this as a _formatted string_ (new since Python 3.6). \n",
    "print(f\"users {max_users} completed {max_complete} TODOs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That’s cool and all, but you’re here to learn about JSON. For your final task, you’ll create a JSON file that contains the completed TODOs for each of the users who completed the maximum number of TODOs.\n",
    "\n",
    "All you need to do is filter todos and write the resulting list to a file. For the sake of originality, you can call the output file `filtered_data_file.json`. There are may ways you could go about this, but here’s one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to filter out completed TODOs \n",
    "# of users with max completed TODOS.\n",
    "def keep(todo):\n",
    "    is_complete = todo[\"completed\"]\n",
    "    has_max_count = str(todo[\"userId\"]) in users\n",
    "    return is_complete and has_max_count\n",
    "\n",
    "# Write filtered TODOs to file.\n",
    "with open(\"filtered_data_file.json\", \"w\") as data_file:\n",
    "    filtered_todos = list(filter(keep, todos))\n",
    "    json.dump(filtered_todos, data_file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 2\n",
    "\n",
    "## Task 0\n",
    "Form a team of 3-4 students. Give your team a cool name like [The Be Sharps](https://www.youtube.com/watch?v=CWbW1jtFQUo) or [The Blernsballs](https://www.youtube.com/watch?v=oQF8rQaIjUE&list=RDzfvpeVe_i1A)... You get the idea. Fill in your name into the corresponding list at GitHub. \n",
    "\n",
    "## Task 1\n",
    "Write a Python program `csv2json` to convert a given CSV file into a JSON file. This conversion should be generic as possible and able to convert different types of CSV files. For the beginning try to make it work with the `lotr_clean.txt` file I uploaded to GitHub. Think about the generic parts. Where do the JSON key names come from? What about different types of separators? Try to build your program from \"simple\" to \"a bit more complex\" and think about how to split the development within your group. Document your program and remember to commit early and commit often.\n",
    "\n",
    "## Task 2\n",
    "Your task is to transform a dataset on movies since 1950. Download the dataset movie_data.json from our Github repository. Write a Python program to:\n",
    "\n",
    "1. read in the data from the JSON file,\n",
    "2. count for each year, how many movies per genre have appeared,\n",
    "3. create a CSV file where for each year, the counts for each genre are listed.\n",
    "\n",
    "Your final CSV should look something like this:\n",
    "\n",
    "year|Action|Adventure|Animation|...\n",
    "-----|------|----------|--------|---\n",
    "1950|39|42|65|...\n",
    "1951|...|...|...|...\n",
    "\n",
    "Bonus: Create some interesting figures (in spreadsheet software, with R or any other visualitation software you know) on the development of genres over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
